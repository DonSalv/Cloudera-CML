{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5ea0ce-8ccf-4fe0-8c91-bc97c04556bb",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# Random Forest algorithm to predict calls volume in a Call Center\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29a2dd-d57f-4ce1-bc30-656f99e8f9f4",
   "metadata": {},
   "source": [
    "This notebook uses Call Center data from 2019. The data is for one year of call logs. The Call Center Managers want to measure its performance based on certain metrics. The managers want to rise the metrics by improving the Workforce Management (WFM) process of scheduling and staffing agents. A machine learning approach is proposed as follows:\n",
    "\n",
    "1. Predict the daily calls volume \n",
    "2. Split the daily calls volume hourly\n",
    "\n",
    "Random Forest algorithm is used to do the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d873d74-eb2f-4292-b0bd-4817d346e9b2",
   "metadata": {},
   "source": [
    "**Importing libraries and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "676fdc58-ba93-4d82-b9a3-de7aeceea898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (18,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec99a00-5224-430c-936b-6c1dca56ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3cf761-1a63-4e07-84f0-b4e12700794c",
   "metadata": {},
   "source": [
    "**Data Preparation**\n",
    "\n",
    "1. The data in the files is monthly data corresponding to call center logs. The calls are registered as soon as they arrive to the call center. Aggregating by seconds or by minutes is useless since the theory of call centers suggest that the daily behavior of a call center is a Poisson model of hourly variable rate.\n",
    "\n",
    "2. Another important thing in the theory of modeling call centers is that the calls volume and the rates are also dependent on the day of the week. The present analysis use the day of the month instead to smooth the seasonality (usually weekly) to monthly seasonality. In this way, the missing data imputation is less prompt to bias.\n",
    "\n",
    "3. A target variable `calls volume` is created to register hourly calls volume. The numerical values of number of abandon calls, prequeue, inqueue, agent_time, postqueue, total_time and global sla achieve per hour are used as covariates (a covariate can be thought as a regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456c90c3-7275-4402-bd1f-45761b53e661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>prequeue</th>\n",
       "      <th>inqueue</th>\n",
       "      <th>agent_time</th>\n",
       "      <th>postqueue</th>\n",
       "      <th>total_time</th>\n",
       "      <th>sla</th>\n",
       "      <th>calls_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>8</th>\n",
       "      <td>60.0</td>\n",
       "      <td>7.730769</td>\n",
       "      <td>113.807692</td>\n",
       "      <td>137.675824</td>\n",
       "      <td>0.126374</td>\n",
       "      <td>235.098901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>15</th>\n",
       "      <th>10</th>\n",
       "      <td>29.0</td>\n",
       "      <td>14.634328</td>\n",
       "      <td>81.955224</td>\n",
       "      <td>158.529851</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>234.858209</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>17</th>\n",
       "      <th>8</th>\n",
       "      <td>29.0</td>\n",
       "      <td>9.376344</td>\n",
       "      <td>109.064516</td>\n",
       "      <td>105.290323</td>\n",
       "      <td>0.204301</td>\n",
       "      <td>192.505376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>20</th>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.941176</td>\n",
       "      <td>63.308824</td>\n",
       "      <td>232.970588</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>291.308824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>10</th>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.889764</td>\n",
       "      <td>30.559055</td>\n",
       "      <td>206.84252</td>\n",
       "      <td>0.165354</td>\n",
       "      <td>241.590551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               abandon   prequeue     inqueue  agent_time postqueue  \\\n",
       "day hour month                                                        \n",
       "8   10   8        60.0   7.730769  113.807692  137.675824  0.126374   \n",
       "18  15   10       29.0  14.634328   81.955224  158.529851  0.119403   \n",
       "5   17   8        29.0   9.376344  109.064516  105.290323  0.204301   \n",
       "16  20   12        5.0  10.941176   63.308824  232.970588  0.161765   \n",
       "17  10   1         9.0   7.889764   30.559055   206.84252  0.165354   \n",
       "\n",
       "                total_time  sla calls_volume  \n",
       "day hour month                                \n",
       "8   10   8      235.098901  1.0        182.0  \n",
       "18  15   10     234.858209  1.0        134.0  \n",
       "5   17   8      192.505376  1.0         93.0  \n",
       "16  20   12     291.308824  1.0         68.0  \n",
       "17  10   1      241.590551  1.0        127.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the yearly dataframe for prediction\n",
    "yearly = get_yearly_frame()\n",
    "yearly.sample(5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e446941-9b12-4794-946e-f80751bc2b00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Using Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670cbcb-9485-44ac-a072-cdff0b07ecfe",
   "metadata": {},
   "source": [
    "Consider the target variable `calls_volume` with historical data of 1 year. The frequency of this variable is hourly (`H`). The covariates for this predictions will be `prequeue`, `inqueue`, `agent_time`, and `postqueue` features of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce09a2eb-34ed-4552-89d1-ec9b68f59d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import RandomForest\n",
    "\n",
    "from darts.metrics import coefficient_of_variation, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a635da3-7474-47d0-903a-b6a4a61f3155",
   "metadata": {},
   "source": [
    "Using Darts library, create the time series for the `calls_volume` target variable and the multi time series for the `features`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75589cee-03b3-43d4-8b0a-e54c4a837f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datafram for the year correctly formatted\n",
    "df = get_formatted_time_series_frame_from(data=yearly, year=\"2019\")\n",
    "\n",
    "# Split Dataframe in Variables and Features\n",
    "variable = df['calls_volume']\n",
    "features = df[['prequeue', 'inqueue', 'agent_time', 'postqueue']] # 'total_time', 'abandon', 'sla'\n",
    "\n",
    "# Get the darts Time Series objects\n",
    "ts_variable = TimeSeries.from_series(variable,\n",
    "                                     freq='H')\n",
    "ts_features = TimeSeries.from_dataframe(features, \n",
    "                                        freq='H')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fe2e6-6d3b-4efe-b744-7e4cae39cda0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Use of Random Forest to forecast hourly calls volume - Self historical test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11e413-fb93-4b55-92d1-f2eb81e05223",
   "metadata": {},
   "source": [
    "As the above description suggest, the weekly seasonal behavior of 7 days impose to look back to the same amount of time in the covariates. This is the reason to select $24\\times 7=168$ lags past covariates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee032205-194e-4a65-b27e-a6d349956a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Works well with 24, 48, and 168 hrs.\n",
    "model_randomforest = RandomForest(lags = 168,\n",
    "                                  lags_past_covariates = 168, \n",
    "                                  random_state = 42\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01629390-a35b-4294-bf78-9c3add1d841a",
   "metadata": {},
   "source": [
    "Train the model in the ts_variable and the ts_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fb73c27-0e9b-4e3b-af7b-8d4cfa7e0332",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_randomforest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_variable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/darts/models/forecasting/regression_model.py:427\u001b[0m, in \u001b[0;36mRegressionModel.fit\u001b[0;34m(self, series, past_covariates, future_covariates, max_samples_per_ts, n_jobs_multioutput_wrapper, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, MultiOutputRegressor)\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m n_jobs_multioutput_wrapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    424\u001b[0m ):\n\u001b[1;32m    425\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided `n_jobs_multioutput_wrapper` wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/darts/models/forecasting/regression_model.py:328\u001b[0m, in \u001b[0;36mRegressionModel._fit_model\u001b[0;34m(self, target_series, past_covariates, future_covariates, max_samples_per_ts, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(training_labels\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m training_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    327\u001b[0m     training_labels \u001b[38;5;241m=\u001b[39m training_labels\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/tree/_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1280\u001b[0m ):\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_randomforest.fit(series=ts_variable,\n",
    "                       past_covariates=ts_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4dfb76-5ca3-4d63-938d-9fa2750e0543",
   "metadata": {},
   "source": [
    "Instead of making new predictions with the model, use it to generate a historical forecast. In this sense, the performance of the algorithm is measure  for one year of data, and the validity of the results will generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e4dd4-cd64-4de7-9394-1a8091f539ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_series = model_randomforest.historical_forecasts(series=ts_variable,\n",
    "                                                      forecast_horizon=7,\n",
    "                                                      stride=1, \n",
    "                                                      retrain=False,\n",
    "                                                      verbose=True,\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b49bb-1ebe-4d2e-8998-d9701b878344",
   "metadata": {},
   "source": [
    "**Visualizing the historical prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6f051-3356-4392-946b-27c1d1b8b464",
   "metadata": {},
   "source": [
    "Plot the last week of the actual data against the predicted historical data. It shows an accuracy of around 84 % according to R-RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f5b8f-b8c1-434c-a58b-71f7e12c93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_and_test(target = ts_variable[-168:],\n",
    "                         prediction= pred_series[-168:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f2f12-b7ac-4e1d-afe6-7aeb3c4882a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Use of Random Forest to forecast hourly calls volume - Testing with features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1fff8-5f81-4227-be10-d2265bd6d249",
   "metadata": {},
   "source": [
    "Since one week is around 2 % of a year, select 5 % of the data to be the test set and the 95% to be the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e826ed-4f40-4885-8387-8175eac33f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train / set\n",
    "train_variable, test_variable = ts_variable.split_after(0.95)\n",
    "train_features, test_features = ts_features.split_after(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8d7ef-7421-4de9-9b91-4ebb04850cf5",
   "metadata": {},
   "source": [
    "The Random Forest model has lags of 168 periods (this mean 1 week) that matches also the past covariates lags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e298f-c9c7-4771-9690-20d071fc051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Works well with 24, 48, and 168 hrs.\n",
    "test_model = RandomForest(lags = 168,\n",
    "                          lags_past_covariates = 168, \n",
    "                          random_state = 42\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74853a-bbaf-4a22-b2c0-af8c0aa27c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model in the corresponding train time series\n",
    "test_model.fit(series=train_variable,\n",
    "               past_covariates=train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0d9e3-26f5-4d41-9f35-7bb84e95dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = test_model.predict(n=len(test_variable),\n",
    "                                series=train_variable,\n",
    "                                past_covariates=ts_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeafd0e-55d5-4d1e-b9bd-329461c2876c",
   "metadata": {},
   "source": [
    "**Visualizing the test prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33adf7da-c516-42fc-b23a-728d1a513f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_and_test(target=test_variable, \n",
    "                         prediction=prediction);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52970a31-5707-4e43-a7e6-cbd2e36fa111",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Resampling the prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a10dc1-bb7f-470e-980a-dc9de3fdb76d",
   "metadata": {},
   "source": [
    "Scheduling staff in the call center gets improved when the aggregation time is for one shift of 8 hours. By just resampling the prediction and test variables, the R-RMSE improves only for 1 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90439b91-3970-4a5a-91d0-751e84685eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_train_variable = train_variable.resample(freq='8h',\n",
    "                                           method='pad')\n",
    "r_test_variable = test_variable.resample(freq='8h', \n",
    "                                         method='pad')\n",
    "r_prediction = prediction.resample(freq='8h',\n",
    "                                   method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f5409-c143-4ef3-9acf-cb1fc985432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_and_test(target= r_test_variable, \n",
    "                         prediction=r_prediction);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53cc58-ad06-4b4b-ac88-0ce7880af9eb",
   "metadata": {},
   "source": [
    "**Plotting the resampled series with train set included**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68915c-8447-443e-816a-8e803e000809",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predict(train_target=r_train_variable[-96:],\n",
    "             test_target=r_test_variable,\n",
    "             prediction=r_prediction,\n",
    "             low_percentile=0.05);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada09c6-ea22-4b93-8e1c-8b33ed4484e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
